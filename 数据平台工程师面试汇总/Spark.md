当 Spark SQL 提交到 Yarn 上时，通常会经历以下步骤：

1. 客户端提交作业
    - 用户通过 Spark 客户端提交 Spark SQL 作业。
2. 启动 ApplicationMaster
    - Yarn 收到请求后，启动一个 ApplicationMaster 进程来管理整个作业的执行。
3. 申请资源
    - ApplicationMaster 向 Yarn 的资源管理器申请所需的资源，包括计算资源（如 CPU、内存）和存储资源。
4. 资源分配
    - 资源管理器根据集群的资源使用情况和申请要求，为作业分配相应的资源。
5. 启动任务
    - 在获得资源后，ApplicationMaster 启动任务执行器（Executor）。
6. 执行任务
    - Executor 加载作业所需的代码和数据，开始执行 Spark SQL 任务。

成功申请到资源后，后续的操作包括：

1. 数据读取与处理
    - Spark 从指定的数据源（如 HDFS、数据库等）读取数据，并进行预处理和转换操作。
2. 执行查询计划
    - 根据 Spark SQL 生成的查询计划，进行数据的过滤、聚合、连接等操作。
3. 中间结果缓存与优化
    - 对于中间结果，可能会进行缓存以提高后续计算的效率，并根据优化规则进行优化。
4. 结果输出
    - 将最终的计算结果输出到指定的目的地，如存储到新的文件、返回给客户端等。

例如，假设一个 Spark SQL 作业是对一个大规模的销售数据进行统计分析，计算每个地区的总销售额。在成功申请到资源后，Spark 会读取销售数据文件，按照地区字段进行分组聚合计算，将中间的每个地区的销售额暂存到内存或磁盘缓存中，最后输出每个地区的总销售额到新的结果文件中。

又例如，对于一个连接多个数据表的复杂查询，成功申请资源后，会分别读取各个表的数据，根据连接条件进行匹配和组合，经过一系列的计算步骤得到最终的连接结果。


---

在 Spark SQL 中，生成查询计划的过程大致如下：

首先，会将输入的 SQL 语句解析为抽象语法树（Abstract Syntax Tree，AST）。这一步的目的是将文本形式的 SQL 转换为一种便于后续处理的结构化表示。

接下来，会对抽象语法树进行逻辑优化。这包括常量折叠、列裁剪、谓词下推等操作，以减少数据处理量和提高执行效率。

然后，基于逻辑优化后的抽象语法树，生成逻辑执行计划。逻辑执行计划描述了查询的逻辑操作，但不涉及具体的执行细节。

为了将逻辑执行计划转换为物理执行计划，Spark 会根据可用的资源和数据分布等因素，选择合适的执行策略。这包括选择具体的连接算法（如哈希连接、排序合并连接等）、数据的分区方式等。

在划分 stage 时，主要依据宽依赖（ShuffleDependency）。宽依赖是指父 RDD 的一个分区会被多个子 RDD 的分区所依赖。当遇到宽依赖时，就会划分出一个新的 stage。

而 task 则是基于数据的分区来划分的。每个分区对应一个 task。

在这个过程中，有以下一些常见的性能优化操作：
1. 分区优化：合理设置数据的分区数量和分区方式，以确保数据分布均匀，减少数据倾斜。
    - 例如，如果某些分区的数据量过大，可能导致该分区的处理时间过长，影响整个作业的性能。
2. 缓存优化：对于经常使用或计算代价高的数据进行缓存，避免重复计算。
    - 比如，一个大表经过一次复杂的转换操作后，如果后续的查询还会频繁使用这个结果，就可以将其缓存起来。
3. 索引优化：如果可能，为经常用于查询和连接的列创建索引，加快数据的查找。
4. 代码生成（Code Generation）：在某些情况下，直接生成特定的执行代码，而不是通过解释执行，提高执行效率。

例如，假设有一个 SQL 查询需要连接两个大表，并且连接条件是基于某个列的值。在生成查询计划时，会根据表的数据量、分布以及可用的资源，决定使用哪种连接算法。如果数据在该列上有较好的分布，可能选择哈希连接，并通过合理的分区方式确保连接操作的高效执行。在划分 stage 时，如果连接操作导致了宽依赖，就会在连接操作之前划分一个新的 stage。对于每个分区的数据，都会生成一个对应的 task 来进行处理。