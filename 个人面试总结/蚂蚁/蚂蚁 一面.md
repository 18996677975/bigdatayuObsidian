### 总结
正常社招面试流程。电话面试。
针对多数项目都进行了 **详细** 地询问。

### 详细记录
- 删除保障，具体实现逻辑，为什么没有将中间路径、临时路径用配置项引入，而是 hardcode
- HDFS 升级，滚动升级、热升级定义，滚动升级具体流程，困难点
- HDFS EC、HDFS RBF
- 机房搬迁，难点，实现逻辑，如何进行机房容灾，跨城性能问题如何处理（`distcp` & `distcp` 如何增量传输，自己如何实现增量传输）
- OneSQL 语法转换工具，具体实现逻辑
- Spark 相关优化做了哪些
- Spark、hive、Trino 差异
- 谓词下推具体实现逻辑
- 一个 Spark SQL 提交到 Yarn 上正式开始执行的流程
- 算法题：编写一个函数对输入的 **单向链表进行排序**，算法越快越好

### 问题复盘
#### 滚动升级
HDFS 滚动升级（HDFS Rolling Upgrade）指的是在不停止 HDFS 服务的情况下，对 HDFS 集群中的各个组件（如 NameNode、DataNode 等）进行逐个升级的过程。

滚动升级允许在升级期间 HDFS 集群继续对外提供服务，减少了因升级导致的服务中断时间。其前提是集群处于高可用（HA）模式。

以下是一般情况下 HDFS 滚动升级的基本步骤（请注意，实际操作前请仔细阅读相关文档和注意事项，并根据实际情况进行适当调整和备份）：
1. 环境准备：拥有一套 HA 高可用集群，并准备好要升级到的新版本安装包。
2. 数据备份（用于升级异常后回滚）：
    - 备份镜像 fsimage：执行`hdfs dfsadmin -rollingUpgrade prepare`。
    - 查询备份进度：执行`hdfs dfsadmin -rollingUpgrade query` ，出现“Proceed with rolling upgrade”表示 fsimage 创建成功。
3. 拷贝当前版本中的关键配置（如 `core-site.xml`、`hdfs-site.xml`、`hadoop-env.sh` 等）到新版本安装包中，并分发安装包到所有节点。
4. 环境变量变更：修改 `/etc/profile` 中环境变量，指向最新的版本。
5. 升级 NameNode：
    - 首先升级 standby 节点，比如先升级 nn2，执行命令：`kill -9 <namenode pid>`（其中 `<namenode pid>` 为要升级的 NameNode 进程 ID），然后执行 `hdfs --daemon start namenode -rollingUpgrade started` 。此时可在 web 页面观察到该节点的版本已升级。
    - 将升级后的 standby 节点转换为 active 状态后重启原 active 节点（nn1）：可以通过相关操作进行主备切换，若切换失败，可主动杀死当前 active 的 NameNode 进程，待确认 standby 节点已转换为 active 状态后，再升级重启原 active 节点的 NameNode 进程。
6. 升级 DataNode：推荐逐个关闭并重启 DataNode 节点进行升级，而不是批量操作。具体步骤如下：
    - 执行指令关闭 DataNode 节点：`hdfs dfsadmin -shutdownDatanode <DATANODE_HOST:IPC_PORT> upgrade` （其中 `<DATANODE_HOST:IPC_PORT>` 为要升级的 DataNode 节点的主机名和 IPC 端口）。
    - 执行指令或通过 jps 指令查看 DataNode 是否已经关闭：`hdfs dfsadmin -getDatanodeInfo <DATANODE_HOST:IPC_PORT>` 。
    - 在对应的 DataNode 节点重启 DataNode 进程：`hdfs --daemon start datanode` 。
7. 确认升级结束：执行命令 `hdfs dfsadmin -rollingUpgrade finalize` 。

在滚动升级过程中，需要注意以下几点：
- 滚动升级从 Hadoop 2.4.0 开始支持。
- 一般只升级 NameNode 和 DataNode，JournalNode 和 ZKFC 相对稳定，通常不升级，因为升级它们可能会导致集群下线。
- 对于大型集群，升级应分阶段进行，以降低风险和影响。
- 在升级前和升级过程中，与集群管理员和相关业务团队保持沟通，确保最小化对生产环境的影响。
- 确保版本兼容性，了解新版本的特性与潜在的配置更改。
- 升级前仔细阅读目标 Hadoop 版本的发行说明，了解升级的特定步骤和已知问题，并制定回滚计划，以便在出现问题时能够快速回滚到之前的稳定版本。

#### 热升级
**HDFS 热升级（Hot Upgrade）** 是指在不停止 Hadoop 分布式文件系统（HDFS）服务的情况下，对其进行版本升级或配置更改等操作。

通常，在传统的升级方式中，可能需要停止整个 HDFS 服务，这会导致系统不可用，影响正在进行的业务和数据处理。而热升级的主要优势在于：
1. 减少服务中断时间：确保系统能够持续运行，不影响用户对数据的访问和处理。  
    例如，在在线数据处理的场景中，如果因为升级而长时间停止服务，可能会导致业务停滞，造成巨大损失。
2. 提高系统可用性：用户无需等待服务恢复就能继续使用 HDFS 进行数据操作。  
    比如说，一些实时数据分析的应用可以不间断地获取数据。

总之，HDFS 热升级能够在不影响系统正常运行的前提下，实现系统的优化和改进。

#### 一个 Spark SQL 提交到 Yarn 上正式开始执行的流程
当 Spark SQL 提交到 Yarn 上时，通常会经历以下步骤：

1. 客户端提交作业
    - 用户通过 Spark 客户端提交 Spark SQL 作业。
2. 启动 ApplicationMaster
    - Yarn 收到请求后，启动一个 ApplicationMaster 进程来管理整个作业的执行。
3. 申请资源
    - ApplicationMaster 向 Yarn 的资源管理器申请所需的资源，包括计算资源（如 CPU、内存）和存储资源。
4. 资源分配
    - 资源管理器根据集群的资源使用情况和申请要求，为作业分配相应的资源。
5. 启动任务
    - 在获得资源后，ApplicationMaster 启动任务执行器（Executor）。
6. 执行任务
    - Executor 加载作业所需的代码和数据，开始执行 Spark SQL 任务。

成功申请到资源后，后续的操作包括：

1. 数据读取与处理
    - Spark 从指定的数据源（如 HDFS、数据库等）读取数据，并进行预处理和转换操作。
2. 执行查询计划
    - 根据 Spark SQL 生成的查询计划，进行数据的过滤、聚合、连接等操作。
3. 中间结果缓存与优化
    - 对于中间结果，可能会进行缓存以提高后续计算的效率，并根据优化规则进行优化。
4. 结果输出
    - 将最终的计算结果输出到指定的目的地，如存储到新的文件、返回给客户端等。

例如，假设一个 Spark SQL 作业是对一个大规模的销售数据进行统计分析，计算每个地区的总销售额。在成功申请到资源后，Spark 会读取销售数据文件，按照地区字段进行分组聚合计算，将中间的每个地区的销售额暂存到内存或磁盘缓存中，最后输出每个地区的总销售额到新的结果文件中。

又例如，对于一个连接多个数据表的复杂查询，成功申请资源后，会分别读取各个表的数据，根据连接条件进行匹配和组合，经过一系列的计算步骤得到最终的连接结果。

---

在 Spark SQL 中，生成查询计划的过程大致如下：

首先，会将输入的 SQL 语句解析为抽象语法树（Abstract Syntax Tree，AST）。这一步的目的是将文本形式的 SQL 转换为一种便于后续处理的结构化表示。

接下来，会对抽象语法树进行逻辑优化。这包括常量折叠、列裁剪、谓词下推等操作，以减少数据处理量和提高执行效率。

然后，基于逻辑优化后的抽象语法树，生成逻辑执行计划。逻辑执行计划描述了查询的逻辑操作，但不涉及具体的执行细节。

为了将逻辑执行计划转换为物理执行计划，Spark 会根据可用的资源和数据分布等因素，选择合适的执行策略。这包括选择具体的连接算法（如哈希连接、排序合并连接等）、数据的分区方式等。

在划分 stage 时，主要依据宽依赖（ShuffleDependency）。宽依赖是指父 RDD 的一个分区会被多个子 RDD 的分区所依赖。当遇到宽依赖时，就会划分出一个新的 stage。

而 task 则是基于数据的分区来划分的。每个分区对应一个 task。

在这个过程中，有以下一些常见的性能优化操作：
1. 分区优化：合理设置数据的分区数量和分区方式，以确保数据分布均匀，减少数据倾斜。
    - 例如，如果某些分区的数据量过大，可能导致该分区的处理时间过长，影响整个作业的性能。
2. 缓存优化：对于经常使用或计算代价高的数据进行缓存，避免重复计算。
    - 比如，一个大表经过一次复杂的转换操作后，如果后续的查询还会频繁使用这个结果，就可以将其缓存起来。
3. 索引优化：如果可能，为经常用于查询和连接的列创建索引，加快数据的查找。
4. 代码生成（Code Generation）：在某些情况下，直接生成特定的执行代码，而不是通过解释执行，提高执行效率。

例如，假设有一个 SQL 查询需要连接两个大表，并且连接条件是基于某个列的值。在生成查询计划时，会根据表的数据量、分布以及可用的资源，决定使用哪种连接算法。如果数据在该列上有较好的分布，可能选择哈希连接，并通过合理的分区方式确保连接操作的高效执行。在划分 stage 时，如果连接操作导致了宽依赖，就会在连接操作之前划分一个新的 stage。对于每个分区的数据，都会生成一个对应的 task 来进行处理。

#### 算法题
编写一个函数对输入的 **单向链表进行排序**，算法越快越好

插入排序：
```python
class ListNode:
    def __init__(self, val=0, next=None):
        self.val = val
        self.next = next

def sort_linked_list(head):
    if not head or not head.next:
        return head

    # 新建一个头节点，用于构建排序后的链表
    sorted_head = ListNode()
    current = head

    while current:
        next_node = current.next
        insert_node = sorted_head

        # 找到插入位置
        while insert_node.next and current.val > insert_node.next.val:
            insert_node = insert_node.next

        # 插入节点
        current.next = insert_node.next
        insert_node.next = current
        current = next_node

    return sorted_head.next
```

归并排序：
```python
class ListNode:
    def __init__(self, val=0, next=None):
        self.val = val
        self.next = next

def merge(left, right):
    # 初始化一个头节点用于构建合并后的链表
    head = ListNode()
    temp = head

    while left and right:
        if left.val <= right.val:
            temp.next = left
            left = left.next
        else:
            temp.next = right
            right = right.next
        temp = temp.next

    # 将剩余的节点添加到合并后的链表中
    if left:
        temp.next = left
    elif right:
        temp.next = right

    return head.next  # 返回合并后的链表头节点（跳过初始化的头节点）

def sort_list(head):
    if not head or not head.next:
        return head

    slow = head
    fast = head

    # 使用快慢指针找到链表的中点
    while fast.next and fast.next.next:
        slow = slow.next
        fast = fast.next.next

    mid = slow.next
    slow.next = None  # 切断链表，分成左右两部分

    left = sort_list(head)  # 对左半部分链表进行排序
    right = sort_list(mid)  # 对右半部分链表进行排序

    return merge(left, right)  # 合并两个有序链表
```