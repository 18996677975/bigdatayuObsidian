### 总结
岗位是 **数据开发**，是数仓方向，和现在的方向不匹配。
问的问题也是 **数仓方向** 的，有较多问题回答较差。

### 详细记录
- 知乎数仓项目介绍
	- 数仓构建思路
	- 业务逻辑
	- 有什么优化方向
	- 模型选择原因、维度选择原因
- 任务优化
	- 数据倾斜判断
	- 资源调整
	- Mapjoin
	- 提前过滤
- Hive、Spark、Trino 对比
- Spark、Trino 架构差异（MPP 是什么）
- 一个 Hive SQL 实际的执行流程详解
	- Map、shuffle、reduce 阶段详解
	- 谓词下推是什么
- 一道 SQL 题

### 问题复盘
#### 数仓构建思路
以下是构建新业务数据仓库的一般思路： 
1. **业务需求理解**：
	- 与业务部门深入沟通，了解新业务的流程、目标、关键指标和业务规则。
	- 例如，对于电商新业务，可能需要关注订单量、销售额、用户活跃度等指标。
2. **数据源评估**： 
	- 确定新业务相关的数据来源，包括内部系统、外部接口等。 
	- 评估数据源的数据质量、数据格式、更新频率等。 
	- 比如，可能有来自销售系统的订单数据、用户系统的用户信息数据等。 
3. **数据建模**： 
	- 选择合适的数据模型，如维度模型或范式模型。 
	- 设计维度表和事实表，建立清晰的数据结构。 
	- 以销售业务为例，可能有产品维度表、时间维度表、销售事实表等。 
4. **数据提取、转换和加载 (ETL)**： 
	- 制定 ETL 流程，从源系统提取数据，并进行清洗、转换和整合。 
	- 处理缺失值、异常值、数据格式转换等。 
	- 比如，将不同格式的日期统一转换为标准格式。 
5. **数据存储设计**： 
	- 根据数据量和访问需求，选择合适的数据库或数据存储技术。 
	- 考虑数据分区、索引优化等。 
	- 对于大规模数据，可能采用分布式数据库存储。 
6. **数据治理和质量管理**： 
	- 建立数据质量监控机制，确保数据的准确性、完整性和一致性。 
	- 制定数据治理策略，明确数据的所有者、使用者和维护者的职责。 
7. **性能优化**： 
	- 对查询和报表进行性能优化，提高数据访问效率。 
	- 例如，通过合理创建索引、优化存储过程等方式。 
8. **安全设计**： 
	- 确保数据的安全性，设置访问权限和数据加密。 
9. **测试和验证**： 
	- 对数据仓库进行全面测试，包括数据准确性、完整性和性能测试。 
10. **部署和维护**： 
	- 将数据仓库部署到生产环境，并进行持续的监控和维护。 
	- 定期进行数据更新和优化。

总之，构建新业务的数据仓库需要综合考虑业务需求、数据来源、技术选型、数据质量和性能等多个方面，以确保数据仓库能够为业务提供有效的支持和决策依据。

#### 模型选择原因、维度选择原因
**维度模型**： 
维度模型是一种以分析决策的需求为出发点构建的数据模型。
它将数据组织成事实表和维度表。事实表通常包含业务的度量值，例如销售金额、订单数量等。 
维度表则包含描述事实的属性，比如时间维度、产品维度、客户维度等。 

维度模型的优点包括： 
- 易于理解和使用，能够直观地反映业务问题。 
- 支持高性能的查询和分析，特别是对于复杂的聚合查询。

例如，在一个销售数据仓库中，销售事实表可能包含销售金额、销售数量等度量，而时间维度表包含年、月、日等信息，产品维度表包含产品名称、类别等信息，客户维度表包含客户名称、地区等信息。 

**范式模型**： 
范式模型是一种基于规范化理论设计的数据模型。 
它通过消除数据冗余和保证数据的一致性来组织数据。 
常见的范式有第一范式（1NF）、第二范式（2NF）、第三范式（3NF）等。 

范式模型的优点包括： 
- 数据的一致性和完整性较好。 
- 节省存储空间。 

例如，在一个学生信息系统中，学生表可能包含学生编号、姓名、年龄等基本信息，课程表包含课程编号、课程名称等信息，选课表则通过学生编号和课程编号的关联来表示学生的选课情况，这样的设计符合范式要求，避免了数据冗余。 

在选择数据模型时，需要考虑以下因素： 
- 业务需求：如果业务主要是进行复杂的分析和查询，维度模型可能更合适；如果更关注数据的一致性和准确性，范式模型可能更优。 
- 数据量和性能要求：对于大规模数据和对查询性能要求较高的场景，维度模型通常表现更好。 
- 数据更新频率：频繁更新的数据可能更适合范式模型。 
- 开发和维护成本：维度模型相对来说更容易理解和开发，但维护成本可能较高；范式模型的开发复杂度较高，但维护可能相对简单。 

总之，要根据具体的业务场景和需求来权衡选择合适的数据模型。

#### Hive、Spark、Trino 对比
Hive、Spark 和 Trino 是三种常用于大数据处理的技术，它们在功能和应用场景上有一些区别： 
- **Hive**：是基于 Hadoop 的一个数据仓库工具，用来进行数据提取、转化、加载，主要用于处理大规模数据的批处理作业，例如网络日志分析。Hive 将用户的 HiveQL 语句通过解释器转换为 MapReduce 作业提交到 Hadoop 集群上，Hadoop 监控作业执行过程，然后返回作业执行结果给用户。Hive 并非为联机事务处理而设计，并不提供实时的查询和基于行级的数据更新操作。 
- **Spark**：是一个快速、通用的大数据处理框架，支持内存计算和分布式计算，可以提高数据处理的速度和效率。它提供了丰富的 API 和工具，支持批处理、流处理、机器学习等多种数据处理方式。除了核心引擎之外，Spark 还包括以下几个库和组件，以支持各种数据处理和分析任务：Spark SQL、Spark Streaming、MLlib、GraphX。
- **Trino**：是一个开源的高性能、分布式 SQL 查询引擎，专门用于对各种异构数据源运行交互式分析查询，支持从 GB 到 PB 的数据量范围。Trino 专门为交互式分析而设计，可以对来自不同数据源的数据进行合并查询，并提供良好的自定义连接器编程扩展框架。Trino 适用于期望响应时间从亚秒到数分钟不等的分析师场景。 

在选择使用哪种技术时，需要考虑以下因素： 
- **数据量和处理需求**：如果数据量较大，需要进行复杂的批处理操作，Hive 可能是一个合适的选择；如果需要进行实时数据处理或机器学习等任务，Spark 可能更适合；如果需要进行交互式查询和分析，Trino 可能是更好的选择。 
- **技术栈和团队技能**：如果团队已经熟悉 Hadoop 生态系统，并且有 Hive 的使用经验，那么继续使用 Hive 可能更方便；如果团队熟悉 Spark 或其他大数据处理框架，那么可以考虑使用相应的技术。 
- **性能和效率要求**：不同的技术在性能和效率方面可能有所差异。如果对查询性能和响应时间有较高要求，需要对不同技术进行测试和评估，以选择最适合的方案。 

综上所述，Hive、Spark 和 Trino 各有其优势和适用场景，在实际应用中，可以根据具体需求和场景选择合适的技术，也可以结合使用多种技术来满足不同的需求。

#### Spark、Trino 架构差异（MPP 是什么）
**Spark 的架构**： 
Spark 主要由以下几个核心组件构成： 
- **Driver Program（驱动程序）**：负责协调和控制整个 Spark 应用的执行。它包含应用的 main 函数，并创建 SparkContext 对象。 
- **Cluster Manager（集群管理器）**：可以是 Spark 自带的 Standalone 模式，也可以是 YARN 或 Mesos 等外部集群管理器，负责资源的分配和管理。 
- **Executor（执行器）**：在工作节点上运行任务，负责实际执行计算任务，并将结果返回给 Driver 程序。 

Spark 的计算基于弹性分布式数据集（RDD）或 DataFrame 等抽象数据结构。它通过将计算分解为一系列的阶段（Stage）和任务（Task），并在集群上并行执行这些任务来实现高效的分布式计算。 

**Trino 的架构**：
Trino 采用了主从架构： 
- **Coordinator（协调器）**：接收用户的查询请求，解析查询语句，生成查询计划，并将任务分配给 Worker 节点。它还负责结果的合并和返回给用户。 
- **Worker Nodes（工作节点）**：执行实际的查询任务，处理数据，并将中间结果返回给 Coordinator 进行最终的结果整合。 

Trino 支持插件式的连接器架构，可以连接多种数据源，如 Hive、MySQL、Cassandra 等，并将不同数据源的数据视为一个统一的查询空间。

**两者在架构上的主要差异**： 
- 数据处理方式：Spark 基于 RDD 或 DataFrame 进行计算，强调数据的转换和操作；Trino 更侧重于查询计划的生成和执行，对多种数据源进行统一的查询处理。 
- 资源管理：Spark 通常依赖外部的集群管理器进行资源分配；Trino 自身对资源的管理相对较为简单，更侧重于查询的优化和执行。 
- 应用场景侧重：Spark 适用于更广泛的大数据处理场景，包括批处理、流处理、机器学习等；Trino 则主要专注于交互式的查询分析。 

例如，在处理大规模数据的复杂批处理和机器学习任务时，Spark 的架构可能更具优势；而在需要快速对多种数据源进行交互式查询分析时，Trino 的架构可能更能满足需求。


**MPP** 即 Massively Parallel Processing（大规模并行处理），是一种计算机体系结构。 

在大数据领域，MPP 架构指的是将任务并行地分布到多个服务器节点上，每个节点都有自己的内存、存储和处理器，并且可以独立地处理一部分数据和计算任务，节点之间通过高速网络进行通信和数据交换，从而实现对大规模数据的快速处理和分析。 

MPP 架构具有以下特点： 
- 高度并行性：可以同时处理多个任务，大大提高了处理效率。 
- 分布式存储：数据分布在多个节点上，实现数据的本地化处理，减少数据传输开销。 
- 高扩展性：通过增加节点数量，可以轻松扩展系统的处理能力和存储容量。 

一些常见的采用 MPP 架构的数据库有 Greenplum、Vertica 等。 
例如，在一个大型电商企业的数据分析场景中，如果需要快速分析大量的用户交易数据以获取销售趋势和用户行为模式，使用 MPP 架构的数据库可以快速并行处理数据，在短时间内得到分析结果，帮助企业做出及时的决策。

#### 谓词下推是什么
**谓词下推**（Predicate Pushdown）是一种在数据库和数据处理框架中常用的优化技术。 

谓词指的是在**查询条件中用于筛选数据的表达式**，例如**比较操作**（大于、小于、等于等）、**逻辑操作**（与、或、非等）。 

谓词下推的核心思想是**将查询中的谓词尽可能地在数据处理的早期阶段进行应用，也就是将筛选条件尽可能地“推”到离数据源更近的地方执行**。 

例如，在一个包含多个处理阶段的系统中，如从数据源读取数据，经过中间的转换和处理，最后进行最终的查询和聚合，如果能够在从数据源读取数据时就应用谓词进行筛选，只读取满足条件的数据，而不是读取全部数据再进行筛选，就可以减少后续处理阶段的数据量，提高整体的处理效率。 

谓词下推的好处包括： 
- 减少数据传输量：在数据源端就筛选掉不需要的数据，减少了在网络中传输的数据量。 
- 降低计算成本：后续处理阶段处理的数据量减少，降低了 CPU 和内存的使用。 
- 提高查询性能：缩短了查询的响应时间，尤其是对于大规模数据处理。 

比如，在一个数据仓库中，对一个包含大量销售记录的表进行查询，要求找出某个时间段内特定地区的销售数据。如果能够在从存储系统读取数据时就应用时间和地区的筛选条件，就可以避免读取大量无关的数据，显著提高查询性能。

#### 开窗函数熟悉
Hive 中的窗口函数是一种强大的数据分析工具，用于**对查询结果的某个窗口（分区或分组内的子集）进行计算和分析**。 

常见的窗口函数包括以下几类： 
1. 排序函数 
	- `ROW_NUMBER()`：为结果集中的每一行分配一个唯一的连续整数编号，编号从 1 开始。 
	- `RANK()`：相同的值会得到相同的排名，但是会跳过后续的排名数字。例如，如果有两个第一名，那么下一个是第三名。 
	- `DENSE_RANK()`：相同的值会得到相同的排名，不会跳过后续的排名数字。例如，如果有两个第一名，那么下一个是第二名。 
2. 聚合函数 
	- `SUM()`、`AVG()`、`MIN()`、`MAX()`等聚合函数，不过是在窗口范围内进行计算。 
3. 偏移函数 
	- `LAG(col, offset, default_value)`：返回当前行之前 `offset` 行的 `col` 值，如果没有则返回 `default_value`。 
	- `LEAD(col, offset, default_value)`：返回当前行之后 `offset` 行的 `col` 值，如果没有则返回 `default_value`。 


窗口函数的基本语法如下： 
```sql
function_name([expression]) OVER ( 
	[PARTITION BY partition_expression] 
	[ORDER BY sort_expression [ASC | DESC]] 
	[window_clause] 
) 
```

`PARTITION BY` 子句用于对结果集进行分组；`ORDER BY` 子句用于在每个分组内对行进行排序；`window_clause` 可以用来指定窗口的范围，如 `ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW` 表示从分区的第一行到当前行的范围。 